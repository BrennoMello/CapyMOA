{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88949364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71849cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 17\n",
    "figsize = (10, 6)\n",
    "\n",
    "no_delayed_batches = [0.1, 0.2, 0.3, 0.4]\n",
    "delay_labels = [10, 50, 80, 100]\n",
    "datasets = [\"SplitMNIST\", \"SplitFashionMNIST\", \"SplitCIFAR10\"]\n",
    "# strategies = [[\"EDR\", \"RER\", \"ER_l\", \"ER_2B\"], [\"EDR\", \"ER_f\"]]\n",
    "strategies = [[\"EDR\", \"RER\", \"ER_l\"], [\"EDR\", \"ER_2B\"], [\"EDR\", \"ER_f\"]]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for no_delayed_batch in no_delayed_batches:\n",
    "        for delay_label in delay_labels:\n",
    "            for value_strategies in strategies:\n",
    "                \n",
    "                _, ax = plt.subplots(figsize=figsize)\n",
    "                for strategy in value_strategies:\n",
    "\n",
    "                    # List all files in the folder (adjust pattern if needed)\n",
    "                    results_folder = f\"results_{dataset}\"\n",
    "                    files = [f for f in os.listdir(results_folder) if fnmatch.fnmatch(f, f\"results_{dataset}_{delay_label}_{no_delayed_batch}_32_5_{strategy}_64_128_5_1_*.json\")]\n",
    "\n",
    "                    accuracies = []\n",
    "                    list_ttt_windowed_task_index = []\n",
    "                    for fname in files:\n",
    "                        with open(os.path.join(results_folder, fname), \"r\") as f:\n",
    "                            data = json.load(f)\n",
    "                            \n",
    "                            acc = np.array(data[\"ttt_metrics_per_window_accuracy\"])\n",
    "                            ttt_windowed_task_index = np.array(data[\"ttt_windowed_task_index\"])\n",
    "                            list_ttt_windowed_task_index.append(ttt_windowed_task_index)\n",
    "                            accuracies.append(acc)\n",
    "\n",
    "                    # Stack all runs into a single array: shape (n_runs, n_steps)\n",
    "                    runs_accuracy = np.stack(accuracies)\n",
    "                    runs_task_index = np.stack(list_ttt_windowed_task_index)\n",
    "\n",
    "                    mean_accuracy = runs_accuracy.mean(axis=0)\n",
    "                    std_accuracy = runs_accuracy.std(axis=0)\n",
    "\n",
    "                    mean_task_index = runs_task_index.mean(axis=0)\n",
    "\n",
    "                    ax.plot(mean_task_index, mean_accuracy, label=strategy)\n",
    "                    ax.fill_between(mean_task_index, mean_accuracy - std_accuracy, mean_accuracy + std_accuracy, alpha=0.3)  \n",
    "                    ax.set_xlabel(\"Task\")\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.legend()\n",
    "\n",
    "                plt.savefig(f\"ocl_plots/results_{dataset}_{delay_label}_{no_delayed_batch}_32_5_{'_'.join(value_strategies)}_64_128_5_1_all.png\", bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68287e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table for final results\n",
    "no_delayed_batches = [0.4]\n",
    "delay_labels = [100]\n",
    "datasets = [\"SplitMNIST\", \"SplitFashionMNIST\", \"SplitCIFAR10\"]\n",
    "strategies = [\"EDR\", \"RER\", \"ER_l\",\"ER_2B\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for no_delayed_batch in no_delayed_batches:\n",
    "        for delay_label in delay_labels:\n",
    "            for strategy in strategies:\n",
    "\n",
    "                results_folder = f\"results_{dataset}\"\n",
    "                files = [f for f in os.listdir(results_folder) if fnmatch.fnmatch(f, f\"results_{dataset}_{delay_label}_{no_delayed_batch}_32_5_{strategy}_64_128_5_1_*.json\")]\n",
    "\n",
    "                list_ttt_cumulative_accuracy = []\n",
    "                list_accuracy_seen_avg = []\n",
    "                list_anytime_accuracy_all_avg = []\n",
    "                list_accuracy_all_avg = []\n",
    "                for fname in files:\n",
    "                    with open(os.path.join(results_folder, fname), \"r\") as f:\n",
    "                        data = json.load(f)\n",
    "                        \n",
    "                        \n",
    "                        ttt_cumulative_accuracy = np.array(data[\"ttt_cumulative_accuracy\"])\n",
    "                        accuracy_seen_avg = np.array(data[\"accuracy_seen_avg\"])\n",
    "                        anytime_accuracy_all_avg = np.array(data[\"anytime_accuracy_all_avg\"])\n",
    "                        accuracy_all = np.array(data[\"accuracy_all\"])\n",
    "                        accuracy_all_avg = accuracy_all.mean(axis=0)\n",
    "\n",
    "                        list_ttt_cumulative_accuracy.append(ttt_cumulative_accuracy)\n",
    "                        list_accuracy_seen_avg.append(accuracy_seen_avg)\n",
    "                        list_anytime_accuracy_all_avg.append(anytime_accuracy_all_avg)\n",
    "                        list_accuracy_all_avg.append(accuracy_all_avg)\n",
    "\n",
    "                # Stack all runs into a single array: shape (n_runs, n_steps)\n",
    "                runs_ttt_cumulative_accuracy = np.stack(list_ttt_cumulative_accuracy)\n",
    "                runs_accuracy_seen_avg = np.stack(list_accuracy_seen_avg)\n",
    "                runs_anytime_accuracy_all_avg = np.stack(list_anytime_accuracy_all_avg)\n",
    "                runs_accuracy_all_avg = np.stack(list_accuracy_all_avg)\n",
    "\n",
    "                mean_ttt_cumulative_accuracy = runs_ttt_cumulative_accuracy.mean(axis=0)\n",
    "                std_ttt_cumulative_accuracy = runs_ttt_cumulative_accuracy.std(axis=0)\n",
    "\n",
    "                mean_accuracy_seen_avg = runs_accuracy_seen_avg.mean(axis=0)\n",
    "                std_accuracy_seen_avg = runs_accuracy_seen_avg.std(axis=0)\n",
    "\n",
    "                mean_anytime_accuracy_all_avg = runs_anytime_accuracy_all_avg.mean(axis=0)\n",
    "                std_anytime_accuracy_all_avg = runs_anytime_accuracy_all_avg.std(axis=0)\n",
    "\n",
    "                mean_accuracy_all_avg = runs_accuracy_all_avg.mean(axis=0)\n",
    "                std_accuracy_all_avg = runs_accuracy_all_avg.std(axis=0)\n",
    "               \n",
    "                print(f\"Dataset: {dataset}, Strategy: {strategy}\")\n",
    "                print(f\"Final TTT Cumulative Accuracy: {mean_ttt_cumulative_accuracy} ± {std_ttt_cumulative_accuracy}\")\n",
    "                print(f\"Final Accuracy Seen Avg: {mean_accuracy_seen_avg} ± {std_accuracy_seen_avg}\")\n",
    "                print(f\"Final Anytime Accuracy All Avg: {mean_anytime_accuracy_all_avg} ± {std_anytime_accuracy_all_avg}\")\n",
    "                print(f\"Final Accuracy All Avg: {mean_accuracy_all_avg} ± {std_accuracy_all_avg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
